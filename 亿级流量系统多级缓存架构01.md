# 《亿级流量系统多级缓存架构10》

高并发多高算高？是JD 阿里 腾讯级别的，还是58 美团级别的，还是瓜子，携程等三先垫上级别的，面试先问问这个。 电商的详情页才是并发最高的。做高并发先做请求的分类，看看有没有对于数据一致性的要求。这一点是解决高并发的一个核心问题。
如果有，则要考虑到数据的分布，数据的同步以及接入的时候不能请求和修改数据的时间太长，还需要考虑用户相应的时间. 数据一致性也分高低级别，高一致性的比如12306，低一致性又叫最终一致性。12306最前台展示的数据也不一定是对的，看见的时候
也并不是即见即所得：还有一张票的时候，点击下单购买，结果怎么没了？第一种原因：看见了但在点击的这个时间段被别人买走了；第二种原因：看见票数等于1就是假的。在看到没有票之后，在返回看一下，票可能还有，显示一段时间，这是的数据是假的；
弱一致性，最终一致性；也可能不存在了。高一致性的性能消耗也比较高。所以面试的时候第一可以反问面试官高并发到底有多高，第二可以问他对于数据一致性的要求高不高。削峰是个关键，最常见的手段是做集群，削峰之前要有个东西先能够扛住峰值的这
个流量。当初nginx做的反向代理其实就是一个削峰的工作，nginx的官方数据是能够扛住50000并发量。而在订票或者秒杀的某个时间点，这个峰值肯定会超过50000，此时nginx还没削峰呢自己就被削了, 所以在很高的并发下nginx做削峰肯定不行的。这
就可以根据qps做技术选型了。对于并发量的描述可以用qps，pv和uv。阿里腾讯并发量很高不太清楚，JD比前两个低多了，阿里腾讯一直飙升无上限，据说阿里每天产生的垃圾请求的数据都有十几T，请求量之大可想而知 瓜子qps=2000美团国美比瓜子稍高
一点，高峰也不会超过5k。某省的公务员考试，并发量是瞬间的，平时没有，交卷瞬间来了30000并发，像个delta函数，也肯定砸崩了。其实得看单个业务线的API的qps具体来谈。究竟能扛住多少并发得看硬件，软件的选择和优化（比如apache 1.x和2.x能
处理的并发量有天壤之别），OS的优化，架构的设计，分层结构等。系统用量估算的时候，单节点的Tomcat不会让他的qps承担超过200，tomcat还是一个比较重量级的容器，所以在前面尽量减少Tomcat的交集。并发量真的大于50000的话，可以通过划分域名
从而划分模块，从而达到分流的目的。划分出来之后，一个模块或者业务就对应着一组服务器，一组服务器能扛住他自己的这套业务就可以了。如果模块已将不能再细分了，此时已经有点扛不住了，对于单一域名的还可以做CDN（分布在全网全球各个节点，是
一个比较成熟的产品，十年前就有，有很多卖这种产品的中间商），缓存静态资源（html，css，图片等分发到全网的各个节点里）也做少量的对一致性要求低的动态缓存（请求到业务服务器里的某个接口所返回的值），现在技术可以做到后端的业务服务器跑
job定时去提交url的数据，更新CDN的缓存内容，另一个方向，CDN也可以定时的去找后台服务器抓取数据更新缓存，这就是第一级别的缓存。CDN做好了之后可以极大地降低qps。CDN只有一个问题，就是怎么去做动态缓存，动态缓存的数据量不能太大了，
否则成本太高了。CDN中动态缓存的数据，对一致性要求一般不是很高，比如列表页，搜索结果页。百度google什么的前几页的搜索结果是一样的，缓存起来了，不是实时搜索的，缓存所在的地方越靠前，系统性能越高，最前面就是CDN。CDN可以对这些数据5-
10 min更新一次，写个Job定时跑。在大型系统中，Job是非常常用的，在大型互联网公司里Job的个数少则几百，多的可能到几万。CDN如果也扛不住，就用到我们的多级缓存了。缓存的核心是基于Redis的，但不仅仅是在Redis上。Redis做缓存一般是
这么搞：请求过来先不去计算，先在Redis中拿，拿不到再去计算。在访问数据之前，不管是SQL，URL或者是某些方法传参都可以作为一些key放到Redis集群里面（很长的SQL也可以做为key，可以做一个摘要算法，但要解决好哈希碰撞的问题）。Redis
集群要由一个客户端来访问，controller可以做客户端，controller调service，service再调Redis集群。给单个tomcat的qps不要超过200，如果超过的话响应时间会变长：50-100qps在集群内网1-2ms，外网也差不多50ms以内，但是超过100qps
之后响应延迟明显会增高。而且tomcat是基于JVM的，其性能跟C语言就没法比了。一般的接入层架构就得像周老师说的那样：单条业务线接入层最前端是一台lvs管着分发请求，hold住流量，转发给后面接好几个nginx。所以lvs和nginx两层都是流量层，
做流量分发（终极解决方案，这就到了7层了，能看见URL了）。这一层的nginx后面，根据业务可以再加一层应用层的nginx，每台接入层的nginx分发请求给多台应用层的nginx，在应用层的nginx上我们可以用C开发nginx模块或者用lua写内嵌脚本了。
C程序的性能很高，但是开发成本也很高，这里主要学习Lua写内嵌脚本，nginx + lua + Redis 和 nginx + lua + Kafka，前者通过nginx跑lua脚本访问Redis集群，Redis集群可以缓存数据和大value，比如整段的的json数据，这样请求
刚到应用层就从缓存里拿到数据给返回回去了，很快；写到Kafka消息队列里，后端的tomcats慢慢去消费。nginx是访问不了Redis和Kafka，所以才需要Lua，他就像个胶水一样。Lua前面不一定非得是nginx。Lua也可以写到Redis里。但是脚本语言，
比如Lua，php，python，不太适合大项目的开发，不好管，不可能50几个人都写脚本语言在一个团队里。至少目前这些语言还不够工程化，工程化表示的是风险可控。Redis里有数据的话，把数据返回应用层的nginx，后者再返回给接入层的nginx，然后
直接返回给client（由于内核arp协议已经调过，而且VIP就设置在其lo的子接口上了，在客户端看来source和destination IP都没问题，就会接受数据包）。每一次请求应用层nginx都会产生大量的socket向Redis建立连接，此时可以考虑在nginx里
再做一级缓存（nginx是很轻量级的应用，随便开几百个nginx跟玩儿似的，这个概念要有），减少应用层nginx到Redis的请求。这里有个问题，那就是所有应用层的nginx机器都是自己的缓存自己看得见，而不是共享的。解决方法就是在接入层的nginx
里面也写入Lua脚本，查看请求要访问的URL（由于nginx工作在七层协议，所以他能看见URL），然后对URL取hash然后取模，根据结果把请求负载到特定的一台或一组应用层nginx上，相同的URL会被转发到相同的应用层nginx上。应用层nginx可以用
Lua Cache或者nginx内置的缓存插件做缓存的读写。URL中有#的话，要把他后面的去掉之后再取hash；URL带？和参数的话，而Tomcat呢？到现在还没干活。这里Tomcat方面的难点是：它怎么去更新Redis中的数据。再一个难点是：数据更新过期时间，
Redis里面的数据更新了，应用层nginx的缓存怎么过期，怎么做同步。这里两层的nginx其实是网关，做的是分流的工作，可以用SpringCloud的Zuul来做。请求过滤：过滤恶意请求，流量限制：请求数，每个节点每个服务上的请求数，这些都可以写在
应用层的nginx上。这些以后都会讲。Redis集群的搭建方式有官方的Redis Cluster，也可以用第三方的组建。一般来说官方的夜曲金鱼比较成熟了。组织Redis集群就是把多节点的Redis分布开。有一种方式或入口，定位某个数据在哪一台服务器上。
对于穿透了Redis之后的流量，可以在接入一层网关，比如springcloud里的Zuul，来分发真正的业务请求到微服务的集群里。这一层的网关要判断请求到底需要哪个微服务来提供服务，其实也就是根据URL去判断的。这个网关他也连接注册中心，可以把
它想象成就是一个反向代理服务器，只是功能已经帮我们实现好了，有点像nginx做反向代理，这里是把不同的请求分发到不同的机器上，只不过它的业务逻辑相对复杂一点，后面sringcloud会用。请求进来之后，内部服务之间的请求还是走服务注册发现。
微服务之间通过注册中心找到互相之间的联系方式的请求进来之后，先跟er/zk这个注册中心交流一下，得知应该转发给哪个微服务，然后再把请求发过去，然后服务之间通过注册中心再来一通调用，最后得到结果之后返回给Zuul网关，完了之后再把结果
反推给用户。根据不同的URL，后面会有不同的Zuul网关，这样就是根据业务线来划分了好多Zuul网关。但再怎么说每台Zuul也是单节点的，所以他也要做HA。请求初次过来的时候会访问到微服务，然后会更新Redis和应用层nginx的缓存。以上都是读
请求，写请求会复杂得多，写请求有的也是update，比如秒杀，抢红包系统（面试中级程序员爱问相关的问题，真被问到了，也是要反问他场景是什么）。电商某sku库存100，一百万个人想买，如何做秒杀？一个简单的方案是：在前端展示的时候先做一层
过滤，比如只能是实名认证的而且登录了才可以买，这样就过滤掉了可能有10万人，这时会展示给用户一个秒杀按钮，在我们设计的时候可以做延迟提交来分流，也就是说点了按钮之后其实没发请求（这不新鲜啊），也就是说第一秒出去30万，第二秒再出去
30万，最后一秒再出去30万，这种分流起码可以过滤掉2/3 qps，成了30万。但是30万对于系统来说也是非常高的qps，我们用上面的这种架构能抗住30万的qps：通过CDN异地多活，lvs，




# Lua + 

## 课程主要内容

l   多级缓存架构模型

l   Redis整合Lua

l   利用Redis+Lua开发分布式锁

l   Openresty 安装部署

l   Nginx下lua脚本访问Nginx内核变量

l   Nginx下利用Lua脚本访问Redis

Lua 是由巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组于1993年开发的一种轻量、小巧的脚本语言，用标准 C 语言编写，其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。

官网：http://www.lua.org/

Redis 在 2.6 版本中推出了脚本功能，允许开发者将 Lua 语言编写的脚本传到 Redis 中执行。使用 Lua 脚本的优点有如下几点:

l   减少网络开销：本来需要多次请求的操作，可以一次请求完成，从而节约网络开销；

l   原子操作：Redis 会将整个脚本作为一个整体执行，中间不会执行其它命令；

l   复用：客户端发送的脚本会存储在 Redis 中，从而实现脚本的复用。

## Redis 与 Lua 整合

### 测试lua执行

#### 在redis中执行简单脚本

登录到客户端后执行

#### hello world

```properties
eval   "return 1+1"    0
#命令    脚本        参数个数
```

#### 参数

```lua
EVAL "local msg='hello world' return msg..KEYS[1]" 1 AAA BBB
```

表是基于1的，也就是说索引以数值1开始。所以在表中的第一个元素就是mytable[1]，第二个就是mytable[2]等等。 表中不能有nil值。如果一个操作表中有[1, nil, 3, 4]，那么结果将会是[1]——表将会在第一个nil截断。

###  独立脚本

#### 获取key的value

```lua
local key=KEYS[1]  

local list=redis.call("get",key);  

return list;
```





#### 读取redis集合中的数据

```lua
local key=KEYS[1]

local list=redis.call("lrange",key,0,-1);

return list;
```





#### 统计点击次数

```lua
local msg='count:'
local count = redis.call("get","count")
if not count then
        redis.call("set","count",1)
end

redis.call("incr","count")

return msg..count+1

```



#### 执行lua脚本

##### 本地执行

```
redis-cli --eval test.lua aaa,bbb

```



##### 远程执行

```lua
redis-cli -h 192.168.2.161 -a密码 --eval /usr/local/luascript/test.lua name age , xiao6
```



### Lua 与 Redis 交互

#### Lua 脚本获取 EVAL & EVALSHA 命令的参数

通过 Lua 脚本的全局变量 KEYS 和 ARGV，能够访问 EVAL 和 EVALSHA 命令的 key [key ...] 参数和 arg [arg ...] 参数。

作为 Lua Table，能够将 KEYS 和 ARGV 作为一维数组使用，其下标从 1 开始。

#### Lua 脚本内部执行 Redis 命令

Lua 脚本内部允许通过内置函数执行 Redis 命令：

redis.call()

redis.pcall()

两者非常相似，区别在于：

若 Redis 命令执行错误，redis.call() 将错误抛出（即 EVAL & EVALSHA 执行出错）；

redis.pcall() 将错误内容返回。

local msg='count:'  local count = redis.call("get","count")  if not count then          redis.call("set","count",1)  end  redis.call("incr","count")  return msg..count+1

### redis WATCH/MULTI/EXEC 与Lua

redis 原生支持 监听、事务、批处理，那么还需要lua吗？

- 两者不存在竞争关系，而是增强关系，lua可以完成redis自身没有的功能

- 在lua中可以使用上一步的结果，也就是可以开发**后面操作依赖前面操作的执行结果的应用**，MULT中的命令都是独立操作

- redis可以编写模块增强功能，但是c语言写模块，太难了，lua简单的多
- 计算向移动数据
- 原子操作

lua脚本尽量短小并且尽量保证同一事物写在一段脚本内，因为redis是单线程的，过长的执行会造成阻塞，影响服务器性能。



### Redis Lua 脚本管理

1.script load  此命令用于将Lua脚本加载到Redis内存中  

2.script exists  scripts exists sha1 [sha1 …]  此命令用于判断sha1是否已经加载到Redis内存中  

3.script flush  此命令用于清除Redis内存已经加载的所有Lua脚本,在执行script flush后,sha1不复存在  

4.script kill  此命令用于杀掉正在执行的Lua脚本

### 死锁

下面代码会进入死循环，导致redis无法接受其他命令。

```lua
eval "while true do end" 0 
```



```lua
127.0.0.1:6379> keys *
(error) BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE.
```

但是可以接受 SCRIPT KILL or SHUTDOWN NOSAVE. 两个命令

SHUTDOWN NOSAVE 不会进行持久化的操作

SCRIPT KILL 可以杀死正在执行的进程



### 生产环境下部署

#### 加载到redis

```lua
redis-cli script load "$(cat test.lua)"
```

得到sha1值

执行

```lua
redis-cli evalsha "7a2054836e94e19da22c13f160bd987fbc9ef146" 0
```



## Openresty Nginx + Lua 

Nginx是一个主进程配合多个工作进程的工作模式，每个进程由单个线程来处理多个连接。

在生产环境中，我们往往会把cpu内核直接绑定到工作进程上，从而提升性能。

### 安装

#### 预编译安装

以CentOS举例 其他系统参照：http://openresty.org/cn/linux-packages.html

你可以在你的 CentOS 系统中添加 openresty 仓库，这样就可以便于未来安装或更新我们的软件包（通过 yum update 命令）。运行下面的命令就可以添加我们的仓库：

      yum install yum-utils

      yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo

然后就可以像下面这样安装软件包，比如 openresty：

   yum install openresty

如果你想安装命令行工具 resty，那么可以像下面这样安装 openresty-resty 包：

      sudo yum install openresty-resty

#### 源码编译安装

#### 下载

http://openresty.org/cn/download.html

`./configure`

然后在进入 `openresty-VERSION/ `目录, 然后输入以下命令配置:

 `./configure`

默认, `--prefix=/usr/local/openresty` 程序会被安装到`/usr/local/openresty`目录。

依赖 `gcc openssl-devel pcre-devel zlib-devel`

安装：`yum install gcc openssl-devel pcre-devel zlib-devel postgresql-devel`

 

您可以指定各种选项，比如

 ```
./configure --prefix=/opt/openresty \

            --with-luajit \

            --without-http_redis2_module \

            --with-http_iconv_module \

            --with-http_postgres_module
 ```





试着使用 `./configure --help` 查看更多的选项。

`make && make install`

#### 服务命令

##### 启动

`Service openresty start`

##### 停止

`Service openresty stop`

##### 检查配置文件是否正确

`Nginx -t`

 重新加载配置文件

`Service openresty reload`

##### 查看已安装模块和版本号

`Nginx -V`

### 测试lua脚本

```nginx
在Nginx.conf 中写入
   location /lua {

        default_type text/html;
        content_by_lua '
           ngx.say("<p>Hello, World!</p>")
         ';
      }
```





### lua-nginx-module

#### 创建配置文件lua.conf

```nginx
   server {
        listen       80;
        server_name  localhost;

   location /lua {

        default_type text/html;

        content_by_lua_file conf/lua/hello.lua;

         }
}
```



#### 在Nginx.conf下引入lua配置

`include       lua.conf;`

#### 创建外部lua脚本

`conf/lua/hello.lua`

内容：

`ngx.say("<p>Hello, World!</p>")`

#### 获取Nginx uri中的单一变量

 ```nginx
     location /nginx_var {

          default_type text/html;

         content_by_lua_block {

             ngx.say(ngx.var.arg_a)

         }
     }
 ```



#### 获取Nginx uri中的所有变量

```lua
local uri_args = ngx.req.get_uri_args()  

for k, v in pairs(uri_args) do  

    if type(v) == "table" then  

        ngx.say(k, " : ", table.concat(v, ", "), "<br/>")  

    else  

        ngx.say(k, ": ", v, "<br/>")  

    end  
end
```





#### 获取Nginx请求头信息

```lua
local headers = ngx.req.get_headers()                         

ngx.say("Host : ", headers["Host"], "<br/>")  

ngx.say("user-agent : ", headers["user-agent"], "<br/>")  

ngx.say("user-agent : ", headers.user_agent, "<br/>")

for k,v in pairs(headers) do  

    if type(v) == "table" then  

        ngx.say(k, " : ", table.concat(v, ","), "<br/>")  

    else  

        ngx.say(k, " : ", v, "<br/>")  

    end  

end  
```





#### 获取post请求参数

```lua
ngx.req.read_body()  

ngx.say("post args begin", "<br/>")  

local post_args = ngx.req.get_post_args()  

for k, v in pairs(post_args) do  

    if type(v) == "table" then  

        ngx.say(k, " : ", table.concat(v, ", "), "<br/>")  

    else  

        ngx.say(k, ": ", v, "<br/>")  

    end  
end
```

#### http协议版本

```lua
ngx.say("ngx.req.http_version : ", ngx.req.http_version(), "<br/>")
```

#### 请求方法

```lua
ngx.say("ngx.req.get_method : ", ngx.req.get_method(), "<br/>")  
```

#### 原始的请求头内容  

```lua
ngx.say("ngx.req.raw_header : ",  ngx.req.raw_header(), "<br/>")  
```



#### body内容体  

```lua
ngx.say("ngx.req.get_body_data() : ", ngx.req.get_body_data(), "<br/>")
```
