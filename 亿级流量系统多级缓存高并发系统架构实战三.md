# 《亿级流量系统多级缓存架构10》

## 前言
处理高并发，先尽量把单节点的性能调到最优，多线程编程的各种技术是这个的基础。而且还要保证数据一致性。随着访问量越来越大，tomcat数量也越来越多，他们做session共享的压力也越来越大，第三方节点的
Redis、memcached会有问题，tomcat多了，本地缓存基本命中不了，每次都会有socket连接连到第三方session数据库，socket连接是个overhead。tomcat机器之间也会同步，彼此之间共享 session，这样做
的消耗也会越来越大，集群内的这种消耗太大的话就没有意义了。解决方法是让相同client的请求总是打到同一个tomcat server上。这就需要Load Balancer解决这个问题了，LB一共有4种方案：1. 硬件 2. lvs
3. haproxy 4. nginx 这里应该选择nginx，因为它可以设置负载均衡策略（lvs也可以：https://blog.csdn.net/m0_37609579/article/details/100609510）这里插一句：二线的电商网站的qps也就是
2-300，1000以内（单个业务系统里），200qps就已经了不得了，500以上公司的市值已经非常高了，真能达到2000qps，连现在的xxhub网站都很难做到，nginx所宣称50000的并发，处理这种请求量足够了。nginx
实现定向流量分发，有两个东西可以做到：1. ip_hash模块，超级高并发的负载下会有问题：数据（流量）倾斜，这是因为我们无法预测请求的source IP，解决方法可以是按照业务线拆分系统成多个，然后再在
tomcat前面加一个网关路由，分析uri实现服务分组，来达到负载均衡。这里的网管跟spring cloud里面的那个zuul还不太一样，这里的是接入层的网关，zuul是业务层的网关，比如两个service之间的互相调用，
微服务内部互相找的网关。2. 访问qq.com/download和qq.com/register的时候，nginx接到请求之后，就针对qq.com这个域名之下两个不同的uri做请求分发 3. 直接把域名改成download.qq.com和
register.qq.com, 然后直接再打到不同的LB上，二级域名这里做分组，接到不同的服务之后，不同的系统就直接被隔离开了，但不影响系统内部的互相调用。4. uri都一样只有参数不同，这样会对于一个资源的
请求造成极高的并发量，页面静态化（可能会懒生成），比如请求打到了tomcat1上，他请求的ID=100，如果已经生成过这个页面了，则tomcat1返回nginx，nginx把页面文件直接返回给用户（nginx的proxy_pass）
但是这么做有一个非常麻烦的问题：1. 页面的维护 2. 数据量的问题， 数据量一大了就不行，更新变得麻烦，这套方案此时就不可取了。 另一个想法：静态部分搞一个模版，tomcat去DB中取出动态数据，然后
生成页面。数据变了，tomcat得去维护数据的变化，也不合适。总之数据量大了的话，致力文件会很困难。  

终极解决方案，对于一个url无法再uri分别转发分割的时候，这时候我们就要考虑一下：有没有必要生成静态文件存在磁盘上吗？其实可以存在内存里，这里就又有两个解决方案：1 tmpfs，在Linux系统内存中的
虚拟磁盘映射，可以理解为使用物理内存当做磁盘，利用这种文件系统，可以有效提高在高并发场景下的磁盘读写，但是重启后数据会丢失。tmpfs是Linux/Unix系统上的一种基于内存的文件系统，类似于ext3, 
ext4。tmpfs可以使用您的内存或swap分区来存储文件。temfs主要存储暂存的文件。他有如下三个优势：  
  1. 动态文件系统的大小。
  2. tmpfs 的另一个主要的好处是它的速度。因为tmpfs位置为内存中，读写几乎可以是瞬间的。
  3. tmpfs 数据在重新启动之后不会保留，因为虚拟内存本质上就是易失的。所以有必要做一些脚本做诸如加载，绑定的操作。tmpfs不具备持久性，重启后数据不保留，原因很明显，它是基于内存的。
在`/dev/shm`目录里写的任何文件会写到内存里，看上去是对文件的操作，其实是对内存的操作。使用的时候才真正去占用物理内存空间，不用的时候，它的内存还是归系统来分配  
https://jpuyy.com/2013/07/tmpfs-usage.html

演示：  
```
[root@Kafka_1 ~]# df -h
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/sda3        18G  4.9G   13G  28% /
 devtmpfs        1.4G     0  1.4G   0% /dev
 tmpfs           1.4G     0  1.4G   0% /dev/shm
 tmpfs           1.4G   17M  1.4G   2% /run
 tmpfs           1.4G     0  1.4G   0% /sys/fs/cgroup
 /dev/sda1       297M  152M  146M  51% /boot
 tmpfs           284M     0  284M   0% /run/user/0
```
每次都是是生成静态文件，如果把这个实时生成出来的文件放在内存，再去治理的时候，由于每次请求都是实时生成的，治理方面的动作几乎就不需要了，因为每次请求都是临时生成了个新的出来。比如页面过期了，
需要删除，这些页面是从内存里面直接扔出去的，并没有落地到磁盘上（有点像thymeleaf这种模版引擎，只是并没有落地到磁盘上）。生成文件这种方案的性能也是不够高的  

可以用nginx + lua。不生成文件的话tmpfs实际上就没什么用。静态的模版可以放在nginx机器的内存中，动态的数据在DB（MySQL or Redis）中，拿过来填充到模版中，但是访问DB需要开关socket、走网络IO
很消耗资源。DB里的数据量太大，不能放到nginx这里，即使连接的是高性能的Redis，每次要向他发起一次连接，IO太多，连接池也会成为瓶颈，怎么办？最高效的方案还是数据缓存到nginx里。nginx的
proxy_cache, 这是磁盘缓存，效率不够高，而且不够灵活，他只能存文件，也就是二进制，没有数据类型。  

我们引出:  
1. `lua_shared_dict` 他不是lua语言实现的，而是nginx内存。`lua_shared_dict shared_data 1m;`这一行的定义应该放在nginx里面去定义
  
  
并发跟qps还并不是一回事

# Lua + 

## 课程主要内容

### Nginx缓存

#### Nginx全局共享内存缓存

在nginx配置文件里：
```
lua_shared_dict shared_data 1m;
```
在lua脚本文件里：
```
local shared_data = ngx.shared.shared_data  

local i = shared_data:get("i")  

if not i then  

    i = 1  

    shared_data:set("i", i)  

    ngx.say("lazy set i ", i, "<br/>")  
end  
 

i = shared_data:incr("i", 1)  

ngx.say("i=", i, "<br/>")
```
可以访问nginx的内存，这是nginx内置的，但在交换的时候，会有性能上的损耗，并发量越高，线程切换的时候损耗也越高。全局的共享缓存，一个线程set的东西，另一个也访问得到。并发不高的时候可以用


#### lua-resty-lrucache

Lua 实现的一个简单的 LRU 缓存，在openresty lib目录下，适合在 Lua 空间里直接缓存较为复杂的 Lua 数据结构：

它相比 ngx_lua 共享内存字典可以省去较昂贵的序列化操作，相比 memcached 这样的外部服务又能省去较昂贵的 socket 操作

lrucache 有两种实现

- resty.lrucache
  - 适合用来缓存命中率高或读操作远远大于写操作的缓存业务
- resty.lrucache.pureffi
  - 适合用来缓存命中率低或需要对key进行频繁增、删操作的缓存业务

```lua
local lrucache = require "resty.lrucache"

-- we need to initialize the cache on the lua module level so that
-- it can be shared by all the requests served by each nginx worker process:
local c, err = lrucache.new(200)  -- allow up to 200 items in the cache



	c:set("dog", 32)
    c:set("cat", 56)
    ngx.say("dog: ", c:get("dog"))
    ngx.say("cat: ", c:get("cat"))

    c:set("dog", { age = 10 }, 0.1)  -- expire in 0.1 sec
    c:delete("dog")

```
https://github.com/openresty/lua-resty-lrucache#name  
以上两种方法，只存热点数据，不存全量数据，全量数据在Redis里面。这样就会造成穿透，造成很多socket连接到Redis。大型项目的Redis中的数据量一般是极大的：几个G甚至是几十个G。这时候
nginx这里的缓存如果全量装不下，就要分机器用集群去装，如果他们各个机器的数据组成了全量数据，也会有数据一致性问题：缓存失效的时候又会雪崩。这里还是缓存热点数据，把存数据的载体从
一个扩充到多个（lvs给nginx做负载），这样缓存的热点数据就变多了，热点数据的策略可以自己去根据业务场景去定义。但这里面还有一个事就是流量分发。在分发流量的时候lvs如何去分发流量，
在不同的nginx上有不同的缓存数据，这就有一个问题，就是缓存极容易被穿透。第一个用户访问id=1，被ip_hash分配到了nginx1，会有一个id=1的被从Redis拿出来，放到nginx1；再有第二个
用户访问id=1，被ip_hash分配到了nginx2，会有一个id=1的被从Redis拿出来，放到nginx2。这样数据就是错乱的，既不是全量数据的副本，也不是热点数据的副本，而且还不是按照数据的分片
来平均分布。在10台nginx上一共缓存1G的数据，每台分到100M，长得不一样，但还有点一样，这就不好说了，但这是可以做到的。失效的时候也不好做级联操作：第一台的id=1的数据更新了，第二台
id=1的失效时间可能是不一样的。也就是说，有的用户看见的库存数是5个，有的就看见了2个。不同机器上的数据乱了，也就是说ip_hash解决不了这个问题了。  

这时候LB就不能用lvs了，它工作在四层协议上，显然看不到uri的参数id，这时候还得用nginx做LB，做定向流量分发：id=100的时候给哪台nginx，id=200的时候转给哪台nginx机器：hash(id) % 
nginx机器数。这样的话就要根据拿到的id这个参数在LB这台nginx上面写策略，这时候可以往高性能的硬件负载均衡器里面去写，厂商就会给提供解决方案；也可以往nginx里面去写，定向流量分发的
逻辑，根据同一个uri（只是参数不同），还能做一次流量分发。下面又有问题了：被LB负载的各台nginx，如何做数据的同步和高可用？高可用好说，但是backup里面没有数据，怎么办？拿lua同步数据！
lua会是一门图灵完备的语言，有强大的类库，数据通信、分析url、然后去数据组装成模版都很简单。定向流量转发的时候可能有数据倾斜，这时候可以增加nginx机器的个数，或者不用backup，而是用
一致性哈希。Redis cluster提供的也是这个高可用的解决方案。每台机器的内存容量限制：承载多少的key，取决于value有多大。nginx设置缓存的时候，这个容量是一定要设置上限的，由于无法预估
value有多大，所以不能以可以的个数为指标。内存能不能盛得下？装不下就损失哈希环一部分的数据，缓存会被穿透，出现故障之后要及时通知运维人员，并配合他们及时修复故障，包括数据的冷启动、
缓存数据的预热等等，那是java层面的东西。高可用有两个层面的东西：1. 写代码去同步数据 2. 一致性哈希环，牺牲一部分数据量，系统架构稍微简单一点。访问量在持续增大的话，一亿个qps，比如
淘宝，可以再在LB前面加一个lvs往后做负载（3-4年前JD的架构）；或者用硬件负载均衡器，可以带有简单逻辑。实在是一个域名：http://taobao.com/item.html?id=XXX 照着这一个域名玩儿死它, 
到了一定上限之后机器和带宽就都扛不住了，这个时候就只能全国各地部署机房，各地用户分别访问各地的机房，每个机房就能扛得住自己的流量了，如果再hold不住，可以在一个城市建两个机房，同一个
URI：item.html, 可以分发到每个机房里。这时候每个机房里同步数据就成了问题（题外话，一鸣哥2000年的时候自己去天津电信托管机器，就看到一个机房里还几百台机器，有搜狐的有新浪的。。。
在软件开发行业，硬件是最不值钱的），两个机房隔得太远的话延迟会比较高，解决方案很简单：拉专线，必须拉专线，不可能走公网。nginx和CDN这两层架构，在域名解析的时候就自带了多级缓存：
本地和DNS供应商那里都有缓存。大公司可以在国内申请备案，走专线网络，不受GFW的限制。这两级缓存就足以支撑亿级流量了。题外话：舆情系统。比如我是个名人，我在新浪、微博、微信等买了舆情
监控服务，这样一旦有我名字的关键字被转发超过一定次数，我就会接收到通知，马上就可以预防流言的传播，因为舆情系统还有追溯的功能，抓出谁第一个制造的流言。瓜子二手车拿openresty做的WAF
（Web Application Firewall）软防火墙（主要是做硬防火墙不需要做或者做不了的复杂逻辑，硬防火墙主要还是比较简单的逻辑规则），一般公司很难做到亿级流量，FLAG的流量可能流量也没有淘宝、
并夕夕那么高，一般先拿一个物理防火墙过滤无效请求，再拿一个openresty做流量的清洗和筛选、做动静分离做集群就够了





##### 实例

```lua
local mycache = require("mycache")  
local count = mycache.get("count") or 0  
count = count + 1  
mycache.set("count", count, 10 * 60 * 60) --10分钟  
ngx.say(mycache.get("count"))     

```

**mycache.lua**

```lua
local lrucache = require("resty.lrucache")  
--创建缓存实例，并指定最多缓存多少条目  
local cache, err = lrucache.new(200)  
if not cache then  
   ngx.log(ngx.ERR, "create cache error : ", err)  
end  
  
local function set(key, value, ttlInSeconds)  
    cache:set(key, value, ttlInSeconds)  
end  
  
local function get(key)  
    return cache:get(key)  
end  
  
local _M = {  
  set = set,  
  get = get  
}  
return _M

```



##### tmpfs

在Linux系统内存中的虚拟磁盘映射，可以理解为使用物理内存当做磁盘，利用这种文件系统，可以有效提高在高并发场景下的磁盘读写，但是重启后数据会丢失。

###### 查看tmpfs命令：

![1569584708275](C:\Users\一明哥\Desktop\tmp\lua\1569584708275.png)

###### 系统默认开启，大小约为物理内存一半



###### 查看物理内存利用情况

![1569584752960](C:\Users\一明哥\Desktop\tmp\lua\1569584752960.png)



tmpfs没有占用内存空间，只有在写入数据的时候才会占用实际的物理内存

###### 调整大小

临时修改方式如下，立即生效但重启后会恢复

![1569584781944](C:\Users\一明哥\Desktop\tmp\lua\1569584781944.png)



###### 永久修改 /etc/fstab文件

![1569584800821](C:\Users\一明哥\Desktop\tmp\lua\1569584800821.png)







#### http_proxy 本地磁盘缓存

```nginx
proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;

server {

     set $upstream http://ip:port

          location / {

                   proxy_cache my_cache;

                   proxy_pass $upstream;
             }

}
```

` /path/to/cache`  #本地路径，用来设置Nginx缓存资源的存放地址

`  levels `         #默认所有缓存文件都放在同一个`/path/to/cache`下，但是会影响缓存的性能，因此通常会在`/path/to/cache`下面建立子目录用来分别存放不同的文件。假设`levels=1:2`，Nginx为将要缓存的资源生成的`key`为`f4cd0fbc769e94925ec5540b6a4136d0`，那么`key`的最后一位0，以及倒数第2-3位6d作为两级的子目录，也就是该资源最终会被缓存到`/path/to/cache/0/6d`目录中

`key_zone`        #在共享内存中设置一块存储区域来存放缓存的`key`和`metadata`（类似使用次数），这样nginx可以快速判断一个request是否命中或者未命中缓存，1m可以存储8000个key，10m可以存储80000个key

`max_size`        #最大cache空间，如果不指定，会使用掉所有disk space，当达到配额后，会删除最少使用的cache文件

` inactive`        #未被访问文件在缓存中保留时间，本配置中如果60分钟未被访问则不论状态是否为expired，缓存控制程序会删掉文件。inactive默认是10分钟。需要注意的是，inactive和expired配置项的含义是不同的，expired只是缓存过期，但不会被删除，inactive是删除指定时间内未被访问的缓存文件

` use_temp_path`   #如果为off，则nginx会将缓存文件直接写入指定的cache文件中，而不是使用temp_path存储，official建议为off，避免文件在不同文件系统中不必要的拷贝

`proxy_cache`     #启用proxy cache，并指定key_zone。另外，如果proxy_cache off表示关闭掉缓存。

### lua-resty-redis访问redis

学习的时候可以搜索"lua-resty-redis"，openresty官网可以学习一下： https://github.com/openresty/lua-resty-redis

`/usr/local/openresty/lualib/resty/redis.lua`中定义了require redis中的各个函数. lua的red:connect可以返回两个值，ok和err，
这是有必要性的，因为java可以有try catch，但是lua没有，他就靠这两个返回值判断是否执行成功。运行时异常，在这种解释型语言里不太容易捕获到。
关键是没有JVM这个沙盒去抓住这个异常，这一点像C和OC，出错了就是error和crash。

#### 踩坑
location /lua {}存在的情况下，再来一个location /luaresty{}后面的被浏览器访问的时候会404.  
修改lua脚本之后需要`service openresty reload`

#### 常用方法

```lua
local cjson = require "cjson"
local redis = require "resty.redis"
local red = redis:new()

local res, err = red:get("key")

local res, err = red:lrange("nokey", 0, 1)

ngx.say("res:",cjson.encode(res))
```



#### 创建连接

```lua
red, err = redis:new()

ok, err = red:connect(host, port, options_table?)
```



#### timeout

```lua
red:set_timeout(time)
```

#### keepalive

```lua
red:set_keepalive(max_idle_timeout, pool_size)
```





#### close

```
ok, err = red:close()
```

 

#### pipeline

```nginx
red:init_pipeline()

results, err = red:commit_pipeline()
```
这里可以做对前面结果的逻辑判断的。比Multi强大

#### 认证

```nginx
    local res, err = red:auth("foobared")

    if not res then

        ngx.say("failed to authenticate: ", err)

        return
end
```





#### redis-cluster支持

https://github.com/steve0511/resty-redis-cluster

 

### redis2-nginx-module 

redis2-nginx-module是一个支持 Redis 2.0 协议的 Nginx upstream 模块，它可以让 Nginx 以非阻塞方式（react模型）直接防问远方的 Redis 服务，同时支持 TCP 协议和 Unix Domain Socket 模式，并且可以启用强大的 Redis 连接池功能。

https://github.com/openresty/redis2-nginx-module

#### test

```nginx
location = /foo {

default_type text/html;

     redis2_query auth 123123;

     set $value 'first';

     redis2_query set one $value;

     redis2_pass 192.168.199.161:6379;

 }
```
单引号和双引号都行。`redis2_query` 和 `redis2_pass`是官方的openresty自带的函数模块。这时候刷新`192.168.1.2/foo`看到+OK，然后查看Redis的key  
`redis2_pass`传递、中转到Redis服务器  
编者按：还可以发送Redis的get请求：
```
location /foo2 {
    default_type text/html;
    redis2_query get one;
    redis2_pass 127.0.0.1:6379;
}
```
重启openresty访问`http://192.168.1.2/foo2`可以看到：`$5 first`
```
location /foo3 {
    default_type text/html;
    set_unescape_uri $key $arg_key1;
    redis2_query get $key;
    redis2_pass 127.0.0.1:6379;
}
```
通过`http://192.168.1.2/foo3?key1=one`可以在浏览器打印出：`$5 first`,就是把URL中key1=后面的那个值（one）放到变量$key  
中，然后再向Redis服务器发送`get one` 然后返回了`$5 first`，lua可以返回两个值，不同于java


#### get

```nginx
location = /get {

default_type text/html;

     redis2_pass 192.168.199.161:6379;

     redis2_query auth 123123;

     set_unescape_uri $key $arg_key;  # this requires ngx_set_misc

     redis2_query get $key;

}
```





#### set

```nginx
# GET /set?key=one&val=first%20value

location = /set {

default_type text/html;

redis2_pass 127.0.0.1:6379;

redis2_query auth 123123;
 

     set_unescape_uri $key $arg_key;  # this requires ngx_set_misc

     set_unescape_uri $val $arg_val;  # this requires ngx_set_misc

     redis2_query set $key $val;

 }
```
通过`http://192.168.1.2/set?key=two&val=second`访问，返回OK，然后可以`redis-cli`之后`get two`验证. location{} 里面不好写各种逻辑，
比如if else，所以redis2_pass 和 redis2_query这些函数不太经常用




#### pipeline



```nginx
     set $value 'first';

     redis2_query set one $value;

     redis2_query get one;

     redis2_query set one two;

     redis2_query get one;

redis2_query del key1;
```

#### list

```lua
    redis2_query lpush key1 C;

    redis2_query lpush key1 B;

    redis2_query lpush key1 A;

redis2_query lrange key1 0 -1;
```





#### 集群

```nginx
upstream redis_cluster {

     server 192.168.199.161:6379;

     server 192.168.199.161:6379;

 }

location = /redis {

default_type text/html;

         redis2_next_upstream error timeout invalid_response;

         redis2_query get foo;

         redis2_pass redis_cluster;
   }
```







## URL一致性哈希负载均衡

有针对性的对url进行一致性hash 定向负载到后端Nginx 

提高Nginx缓存系统命中率

#### nginx url_hash

Nginx第三方模块，在转发请求时如果后端服务器宕机，会导致503服务器未知错误，中转方面的错误。lua脚本可以手动的控制中转到哪一台服务器上  
lua版的http client可以检测nginx后的各个机器是否存活，存活的话就让它参与哈希，否则不让它参与哈希。比如后台有5台服务器，就拿哈希值跟
5取模，0-4分发，如果第三方模块和健康检查模块没有建立数据通信的话，就做不到动态的分配，而且想做一致性哈希环的高可用，纯的URL一致性哈希
也做不到，只是取了个哈希值返回来。lua可以让我们自己写代码实现一致性哈希。这里要自己引入lua相关的依赖: 直接从https://github.com/ledgetech/lua-resty-http/tree/master/lib/resty
下载，然后放到/usr/local/openresty/lualib/resty 下面。http.lua就是个http的客户端，作用就是实现http协议，这里要配置一下DNS，也
就是在location里面加一句`resolver 8.8.8.8;`，就可以访问或中转到一些网络上的API（支持http的，如Spring Cloud），这样就可以拿nginx
调用微服务了，nginx成了入口的一个门面，如果知道具体的服务在哪儿，就可以绕过Spring Cloud的网关直接请求

#### lua-resty-http
类似于http-client（封装了http协议的java客户端），实现了http协议的lua客户端，可以远程去访问数据，手动实现反向代理。请求打到我这里，接到之后，帮对方请求后台服务器

### GitHub主页

https://github.com/ledgetech/lua-resty-http

### 安装组件

wget https://raw.githubusercontent.com/pintsized/lua-resty-http/master/lib/resty/http_headers.lua  

wget https://raw.githubusercontent.com/pintsized/lua-resty-http/master/lib/resty/http.lua 



 

```lua
local http = require("resty.http")  

local httpc = http.new()  
  
local resp, err = httpc:request_uri("http://www.sogou.com", {  
    method = "GET",  
    path = "/sogou?query=resty.http",  
    headers = {  
        ["User-Agent"] = "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.111 Safari/537.36"  
    }  
})  
  
if not resp then  
    ngx.say("request error :", err)  
    return  
end  
  
 
ngx.status = resp.status  
  
  
for k, v in pairs(resp.headers) do  
    if k ~= "Transfer-Encoding" and k ~= "Connection" then  
        ngx.header[k] = v  
    end  
end  
  
ngx.say(resp.body)  
  
httpc:close()

```
返回的sogou原始header中有的资源有的是需要的，可以做一个匹配，如果不需要，不赋值也可以，有一个默认的header直接传回去。  
这就可以中转请求到后端的服务器了
http（location大括号里面）模块加入

```
resolver 8.8.8.8;
```
use Google's open DNS server for an example


### lua-resty-http实现一致性hash负载均衡

```lua
local http = require "resty.http"
local httpc = http.new()

local hosts = {"192.168.1.111:8080", "192.168.1.112:8080"}

local item_id = ngx.var.arg_id

local id_hash = ngx.crc32_long(item_id)
local index = (id_hash % 2) + 1

local resp, err = httpc:request_uri("http://"..hosts[index], {
        method = "GET",
        headers = {
                 ["User-Agent"] = "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.111 Safari/537.36"
        }
})

if not resp then
        ngx.say("Request error: ", err)
end

ngx.say(resp.body)
httpc:close()
```
lua的表是从index = 1开始的. `hosts = {"192.168.1.111:8080", "192.168.1.112:8080"}`这一行如果是80端口，可以只写IP. path在这里的httpc:request_uri中没用上  
这样就使用lua实现了自定义规则的定向流量转发（但现在这个2台机器的2，是写死了的）。 这里就可以判断URL上有没有一些不正常的信息，比如SQL注入、绕过权限、狂刷页面、放爬虫
等（DDOS到不了这一层，他只是建立连接而不发请求，那东西应该在防火墙那边去防）。如果单纯用负载均衡器的话，是很难扩展的。httpc:request_uri这里也可以发Redis请求，如：
red:get("key")，还可以发基于Spring Cloud的http请求
## 模板实时渲染 lua-resty-template

https://github.com/bungle/lua-resty-template

如果学习过JavaEE中的servlet和JSP的话，应该知道JSP模板最终会被翻译成Servlet来执行；

而lua-resty-template模板引擎可以认为是JSP，其最终会被翻译成Lua代码，然后通过ngx.print输出。   

lua-resty-template大体内容有： 

l   模板位置：从哪里查找模板； 

l   变量输出/转义：变量值输出； 

l   代码片段：执行代码片段，完成如if/else、for等复杂逻辑，调用对象函数/方法； 

l   注释：解释代码片段含义； 

l   include：包含另一个模板片段； 

l   其他：lua-resty-template还提供了不需要解析片段、简单布局、可复用的代码块、宏指令等支持。

基础语法

l   {(include_file)}：包含另一个模板文件；

l   {* var *}：变量输出；

l   {{ var }}：变量转义输出；

l   {% code %}：代码片段；

l   {# comment #}：注释；

l   {-raw-}：中间的内容不会解析，作为纯文本输出；

### lua代码热加载

在http模块中加入

```
lua_code_cache off;
```

reload后Nginx会提示影响性能，记得在生产环境中关掉。

![1569585068623](C:\Users\一明哥\Desktop\tmp\lua\1569585068623.png)

### 测试

### 一、初始化

```
-- Using template.new
local template = require "resty.template"
local view = template.new "view.html"
view.message = "Hello, World!"
view:render()

-- Using template.render
-- template.render("view.html", { message = "Hel11lo, Worl1d!" })


```

### 二、执行函数，得到渲染之后的内容

```
local func = template.compile("view.html")  

local content = func(context)  

ngx.say("xx:",content) 
```





### resty.template.html

```lua
local template = require("resty.template")
local html = require "resty.template.html"

template.render([[
<ul>
{% for _, person in ipairs(context) do %}
    {*html.li(person.name)*} --
{% end %}
</ul>
<table>
{% for _, person in ipairs(context) do %}
    <tr data-sort="{{(person.name or ""):lower()}}">
        {*html.td{ id = person.id }(person.name)*}
    </tr>
{% end %}
</table>]], {
    { id = 1, name = "Emma"},
    { id = 2, name = "James" },
    { id = 3, name = "Nicholas" },
    { id = 4 }
})

```

### 模板内容

```html
<!DOCTYPE html>
<html>
<body>
  <h1>{{message}}</h1>
</body>
</html>

```

### 多值传入

```lua
template.caching(false)
local template = require("resty.template")
local context = {
    name = "lucy",
    age = 50,
}
template.render("view.html", context)

```

### 模板内容

```lua
<!DOCTYPE html>
<html>
<body>
  <h1>name:{{name}}</h1>
  <h1>age:{{age}}</h1>
</body>
</html>

```



### 模板管理与缓存

模板缓存：默认开启，开发环境可以手动关闭

```template.caching(true)```

模板文件需要业务系统更新与维护，当模板文件更新后，可以通过模板版本号或消息通知Openresty清空缓存重载模板到内存中

`template.cache = {}`





### 完整页面



```lua
local template = require("resty.template")
template.caching(false)
local context = {
    title = "测试",
    name = "lucy",
    description = "<script>alert(1);</script>",
    age = 40,
    hobby = {"电影", "音乐", "阅读"},
    score = {语文 = 90, 数学 = 80, 英语 = 70},
    score2 = {
        {name = "语文", score = 90},
        {name = "数学", score = 80},
        {name = "英语", score = 70},
    }
}

template.render("view.html", context)

```

### 模板

```html
{(header.html)}  
   <body>  
      {# 不转义变量输出 #}  
      姓名：{* string.upper(name) *}<br/>  
      {# 转义变量输出 #}  
      简介：{{description}}
           简介：{* description *}<br/>  
      {# 可以做一些运算 #}  
      年龄: {* age + 10 *}<br/>  
      {# 循环输出 #}  
      爱好：  
      {% for i, v in ipairs(hobby) do %}  
         {% if v == '电影' then  %} - xxoo
            
              {%else%}  - {* v *} 
{% end %}  
         
      {% end %}<br/>  
  
      成绩：  
      {% local i = 1; %}  
      {% for k, v in pairs(score) do %}  
         {% if i > 1 then %}，{% end %}  
         {* k *} = {* v *}  
         {% i = i + 1 %}  
      {% end %}<br/>  
      成绩2：  
      {% for i = 1, #score2 do local t = score2[i] %}  
         {% if i > 1 then %}，{% end %}  
          {* t.name *} = {* t.score *}  
      {% end %}<br/>  
      {# 中间内容不解析 #}  
      {-raw-}{(file)}{-raw-}  
{(footer.html)}  

```







### layout 布局统一风格

使用模板内容嵌套可以实现全站风格同一布局

#### lua

`local template = require "resty.template"`

一、

```
local layout   = template.new "layout.html"

layout.title   = "Testing lua-resty-template"

layout.view    = template.compile "view.html" { message = "Hello, World!" }

layout:render()
```





二、

```
template.render("layout.html", {

  title = "Testing lua-resty-template",

  msg = "type=2",

  view  = template.compile "view.html" { message = "Hello, World!" }

})
```





三、

此方式重名变量值会被覆盖

```
local view     = template.new("view.html", "layout.html")

view.title     = "Testing lua-resty-template"

view.msg = "type=3"

view.message   = "Hello, World!"

view:render()
```





四、

可以区分一下

```
local layout   = template.new "layout.html"

layout.title   = "Testing lua-resty-template"

layout.msg = "type=4"

local view     = template.new("view.html", layout)

view.message   = "Hello, World!"

view:render()
```





 

#### layout.html

```
<!DOCTYPE html>

<html>

<head>

​    <title>{{title}}</title>

</head>

<h1>layout</h1>

<body>

​    {*view*}

</body>

</html>
```





#### view.html·

`msg:{{message}}`

 

#### 多级嵌套

lua

```
local view     = template.new("view.html", "layout.html")

view.title     = "Testing lua-resty-template"

view.message   = "Hello, World!"

view:render()

view.html

{% layout="section.html" %}
```





<h1>msg:{{message}}</h1>


section.html

<div
id="section">

​    {*view*} - sss

</div>

layout.html

<!DOCTYPE html>

<html>

<head>

​    <title>{{title}}</title>

</head>

<h1>layout {{msg}}</h1>
<body>

​    {*view*}

</body>

</html>





## IDE Lua 脚本调试

### EmmyLua插件

https://github.com/EmmyLua/IntelliJ-EmmyLua

https://emmylua.github.io/zh_CN/

### LDT 基于eclipse

https://www.eclipse.org/ldt/

 

 

## 限流

### 限流算法

#### 漏桶算法

​                                                  

#### 令牌桶算法

   

#### 计数器

常见的连接池、线程池等简单粗暴的按照数量限流的方式

### Tomcat限流

server.xml配置文件中的Connector节点

<Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" 

maxConnections="800" acceptCount="500" maxThreads="400" />

l   maxThreads：tomcat能并发处理的最大线程数

l   acceptCount：当tomcat起动的线程数达到最大时，接受排队的请求个数，默认值为100 

l   maxConnections：瞬时最大连接数，超出会排队等待

 

## Lua 开源项目

### WAF

https://github.com/unixhot/waf

https://github.com/loveshell/ngx_lua_waf

 

l   防止 SQL 注入，本地包含，部分溢出，fuzzing 测试，XSS/SSRF 等 Web 攻击

l   防止 Apache Bench 之类压力测试工具的攻击

l   屏蔽常见的扫描黑客工具，扫描器

l   屏蔽图片附件类目录执行权限、防止 webshell 上传

l   支持 IP 白名单和黑名单功能，直接将黑名单的 IP 访问拒绝

l   支持 URL 白名单，将不需要过滤的 URL 进行定义

l   支持 User-Agent 的过滤、支持 CC 攻击防护、限制单个 URL 指定时间的访问次数

l   支持支持 Cookie 过滤，URL 与 URL 参数过滤

l   支持日志记录，将所有拒绝的操作，记录到日志中去

### Kong 基于Openresty的流量网关

https://konghq.com/

https://github.com/kong/kong

Kong 基于 OpenResty，是一个云原生、快速、可扩展、分布式的微服务抽象层（Microservice Abstraction Layer），也叫 API 网关（API Gateway），在 Service Mesh 里也叫 API 中间件（API Middleware）。

Kong 开源于 2015 年，核心价值在于高性能和扩展性。从全球 5000 强的组织统计数据来看，Kong 是现在依然在维护的，在生产环境使用最广泛的 API 网关。

Kong 宣称自己是世界上最流行的开源微服务 API 网关（The World’s Most Popular Open Source Microservice API Gateway）。

核心优势：

l   可扩展：可以方便的通过添加节点水平扩展，这意味着可以在很低的延迟下支持很大的系统负载。

l   模块化：可以通过添加新的插件来扩展 Kong 的能力，这些插件可以通过 RESTful Admin API 来安装和配置。

l   在任何基础架构上运行：Kong 可以在任何地方都能运行，比如在云或混合环境中部署 Kong，单个或全球的数据中心。

   

### ABTestingGateway

https://github.com/CNSRE/ABTestingGateway

ABTestingGateway 是一个可以动态设置分流策略的网关，关注与灰度发布相关领域，基于 Nginx 和 ngx-lua 开发，使用 Redis 作为分流策略数据库，可以实现动态调度功能。

ABTestingGateway 是新浪微博内部的动态路由系统 dygateway 的一部分，目前已经开源。在以往的基于 Nginx 实现的灰度系统中，分流逻辑往往通过 rewrite 阶段的 if 和 rewrite 指令等实现，优点是性能较高，缺点是功能受限、容易出错，以及转发规则固定，只能静态分流。ABTestingGateway 则采用 ngx-lua，通过启用 lua-shared-dict 和 lua-resty-lock 作为系统缓存和缓存锁，系统获得了较为接近原生 Nginx 转发的性能。

l   支持多种分流方式，目前包括 iprange、uidrange、uid 尾数和指定uid分流

l   支持多级分流，动态设置分流策略，即时生效，无需重启

l   可扩展性，提供了开发框架，开发者可以灵活添加新的分流方式，实现二次开发

l   高性能，压测数据接近原生 Nginx 转发

l   灰度系统配置写在 Nginx 配置文件中，方便管理员配置

l   适用于多种场景：灰度发布、AB 测试和负载均衡等