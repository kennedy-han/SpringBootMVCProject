# 亿级流量系统多级缓存高并发系统架构实战二

## CDN
想达到负载均衡的效果还不想使用任何一台服务器该如何做？域名（CDN）。CDN网络是在用户和服务器之间加一层cache。域名要解析为IP才能去访问网站。通过一个浏览器（其他应用程序后面讲），怎么把一个
域名变成一个IP地址？浏览器跑在一个操作系统上，当输入一个域名胡扯之后，他先从`/etc/hosts`文件里查找该域名所对应的IP，如果找到了，浏览器就直接使用这个IP；如果没有，就从操作系统底层的DNS
缓存中去找，这些缓存都是原来在互联网上请求过的，然后缓存到本地来的。如果还是没有，则去DNS服务器地址查找，然后缓存到本地，而DNS服务器的地址在网卡上配了：114.114.114.114.如果没有配置或者
配的不对，就会得不到正确的域名解析。DNS只是存储了域名对IP的键值对，各个运营商什么都有DNS服务器、互联网公司如Google会自己搭建DNS服务器，他们的数据从哪里来呢？购买域名的时候，会配置DNS服
务器，这个DNS也有域名解析的数据，他接到注册之后，会广播，提交到全网的DNS（包括根），然后浏览器就能拿到域名对应的IP了。通过浏览器访问域名，必须得是域名在公网能够正确解析才可以。  

这里面有个问题：1. 刚配置的那一台DNS服务器压力会很大 2. 广播的时候，怎么才能广播到所有全网这些服务器上? 需要多长时间（小于24小时，有点像zk，不会立即生效）  

这一台配置的DNS服务器是通过一个IP地址映射到一组机器上，统一的出口。一段特别短的数据就特别容易及时反馈回来。还有一个域名缓存的问题，最初的配置域名改了怎么办？配置的DNS服务器域名解析的时候，
那里面有一个TTL，经过多长时间就过期，要重新广播。闲篇扯完回归正题。  

如果一个域名发到DNS之后可以返回多个IP地址，则就可以根据域名做负载均衡了。而DNS技术是支持这一点的（域名申请时配置的得是个只能DNS服务器地址）。但是要告诉他，究竟返回这几个IP中的哪一个？
可以登陆智能DNS进行配置。智能DNS服务器可以得到客户端的IP，并分析出他的地点，在不同地区的机房的机器就接受来自各自地区的请求，以达到低延迟。有这么个"一秒定律"： 刷新页面的时候，来自比较近的
服务器的延迟比较低，这里不是物理上的距离，而是算的网络距离，联通和电信的两台机器，即便是物理距离不远，通信的延迟也是很高的。知道IP就知道是哪个ISP提供商，像是这种视频、直播app，他们在全网
的节点的搭建是非常多的，目的就是达到"一秒定律"，不管是直播还是录播的短视频，能做到一点在一秒内就能打开，一刷在下一秒就能切换到下一个，那就需要拉近距离，第一就是区域的距离（物理和网络的距离，
海南的用户别访问哈尔滨的服务器，电信的访问电信的，联通的访问联通的，独立的区域内还要部署跨ISP的多节点的访问），这实际就是把集中在一起的机房机器分散到全国各地去，不同地区的用户访问的nginx
服务器也不一样，这就可以快速响应用户的请求，这种技术就叫CDN。跟没有CDSN的区别就是原来各个nginx都在我们自己家的机房里，现在各个nginx不在一个地方，根据地点和IP分配到各地去，目的就是
"一秒定律"。过去是"三秒法则"，现在随着网络越来越好、4G变5G，宽带也越来越便宜，动不动就是几百兆的，虽然带宽上来了，但是延迟下不来也不行，比如网游和视频会议，这就需要全球去部署nginx节点。
接下来考虑一个问题，这些nginx服务器上放什么？

全球各地的nginx上可以放：html、js、css、静态图片。可以做基于反向代理的负载均衡、动静分离、写脚本做软防火墙、生成验证码等等。还可以放音视频点播资源、大文件下载。如何治理这些静态资源成了个
问题。解决这个问题需要开发一个应用系统DNS服务（或者使用云服务/zk），放在应用服务器集群和各个nginx之间，三者同步数据的时候要开socket走各种网络IO（netty）。跨机房或者异地的数据备份、请求
备份、提速。异地多活跟CDN很像。服务器里的数据存在哪儿呢？nginx有内存缓存，可以用：  
1. lua_shared_dict做全局缓存，他借助的是lua语言，拿到ngx.shared.shared_data,访问的是nginx内存里面的缓存数据  
2. lua-resty-lrucache： lua实现的一个简单的LRU缓存，适合在Lua空间里直接缓存比较复杂的Lua数据结构 网页链接他相比ngx_lua共享内存字典可以省去昂贵的序列化操作，相比memcached这样的外部
   服务又能省去较昂贵的socket操作
3. http_proxy_cache 本地磁盘缓存，缓存静态文件用的，非常方便，而且别看是磁盘缓存，他也可以做到高性能。把内存空间映射成磁盘的方式解决读取本地磁盘速度的问题。CDN的nginx的http_proxy_cache
   要有过期时间或者有能力去获取已过期或不存在的数据，对于这些数据要从nginx文件服务器（可能是nginx+FastDFS？）拿过去。CDN就能极大的过滤请求、削峰、request清洗。题外话：app现在没有这么火
   了，因为开发和推广成本太高：以前3-5块钱就能让一个用户装上app，现在得20-30块钱，而且每天在用的app就那么几个。 app作为client，会直接访问服务接口，因为UI在发布APP的时候就已经开发好了，
   很少有更新，这些文件都已经内置装好了web的这种css、js，还可以做热更新：到服务器端把代码拉到app执行更新：lua脚本代码做热更新。app store和google play至少是以前，只支持全量更新。缓存的
   UI画面已经存在app包里面了，数据上的缓存就更能做了，因为整个应用都是我们做的。Lua在游戏界是很厉害的，《魔兽世界》除了3D引擎和游戏骨架是用C和C++写的，剩下的UI的组织都是Lua写的，可以看
   《魔兽世界》的客户端，解开之后全是Lua代码
   
静态请求是有过期时间的，而动态请求没有。动态请求，比如文章、商品、个人信息，其中文章谁看都一样（都是马伊琍她老公），商品就不太一样了，可能会有库存数据，不同人不同时间看到的商品显示可能不一样
看看库存和价格可能改变，所以商品数据能不能分发到CDN网络上？可以也不可以。说可以的：  

商品服务可以把数据库中的商品信息生成静态文件，分发到全网，棘手的问题，商品库存、评论是实时更新的，如果对一致性要求不高的话，也是可
以的。我们其实可以只把库存（或者经常变化的评论啥的）5秒更新一次。商品服务拿到变化的数据，再编辑，把数据放到该放的页面位置，再全网更新这个静态页面（也可以异步更新，放MQ）。还可以做成ajax异步
请求，更新的内容量就变小了、复杂度变低。现在的问题是文件变多了怎么办？库存和价格数据可以做数据闭环：就是库存和价格可以从它们各自的原始库中取出来，在本地做一个副本，取的时候直接从本地取出。
评论和推荐什么的可以再独立分别的组，当网页被用户打开的时候做异步懒加载，前端检测屏幕读到哪儿了，然后再去load。异步加载也有很多种方式：上来就加载还是看用户读到哪了再加载等等。一上来就把所有
页面信息都发给用户可能会造成页面打开的时候卡死，全白屏，然后好不容易缓冲出来之后发现信息大都是用户不想看的。就应该做响应式的惰性加载  

说不可以的：  

上亿个商品就麻烦了。html文件引入通用的css和js。网页的头部区域有商品名称、库存（数据经常变，所以ajax）、详情介绍（异步，ajax）、评论（ajax）、推荐（ajax）、用户状态的请求（ajax）。。。
这就至少5-6个文件了，对于1000个商品，生成出5-6000个文件来，结构上做一点变化就要对所有的商品的文件做修改，全量重新生成，对于文件的治理就变得非常的复杂。说他不行时因为没法适应商品详情页过多这
种情况，这些文件都存在哪？在CDN这个领域里，就没有更新这一说，就是删了再重新上传，这些文件会有多大？假设只有3G的数据，CDN肯定要做负载均衡，不能只有一个节点，有多少台机器？至少几十上百台，淘宝
双十一当天就有几十TB的数据从CDN网络走出去，一次全量更新所有的机器负载都会特别大，因为缓存失效，缓存失效的动作就是先删再传，咱们的覆盖也是这么干的（不是做文件对比、增量更新），IO全部被占满，
而且整个网络会非常忙，传的快了整个集群别干别的了，传的慢了，一致性会降得更低。这里问题非常大，对大型电商不可以，中小型（或者垂直）电商可以这样，没多少并发。

高并发的系统架构，没有解决某个具体问题的银弹，不同的场景之下有不同的技术选型。CDN应用场景：html、css、img、js股价中包含的静态资源。app内需要的img、html。期望-网络爬虫。大文件下载
不适用：私密商业数据：企业交易数据、资产类、知识产权（图库，哪家公司没被视觉中国起诉过出门都不好意思跟人聊天）、用户个人静态数据。包含有逻辑的请求、需要鉴权、长连接、reactor模型、即时通讯（
手机直播可以做）

根据地点、进行配置给出IP  